{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonar Data with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBLEM DESCRIPTION:\n",
    "\n",
    "The file “dataminesrocks.csv” contains 208 patterns obtained by 1)bouncing sonar signals off a metal cylinder at various angles and under various conditions, and 2) from bouncing sonar signals off rocks under similar conditions. The transmitted sonar signal is a frequency-modulated chirp, rising in frequency. The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock.\n",
    "\n",
    "Each pattern is a set of 60 features in the range 0.0 to 1.0. Each feature representing the energy within a particular frequency band, integrated over a certain period of time. \n",
    "\n",
    "The label associated with each record contains \"Rock\" or \"Mine\".\n",
    "\n",
    "Three trained human subjects were each tested on 100 signals, chosen at random from the set of 208 returns used to create this data set. Their responses ranged between 88% and 97% correct. However, they may have been using information from the raw sonar signal that is not preserved in the processed data sets presented here.\n",
    "\n",
    "Can we design a model that improves the above performance?\n",
    "\n",
    "References: \n",
    "\n",
    "https://datahub.io/machine-learning/sonar#readme\n",
    "https://www.openml.org/d/40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>attribute_6</th>\n",
       "      <th>attribute_7</th>\n",
       "      <th>attribute_8</th>\n",
       "      <th>attribute_9</th>\n",
       "      <th>...</th>\n",
       "      <th>attribute_52</th>\n",
       "      <th>attribute_53</th>\n",
       "      <th>attribute_54</th>\n",
       "      <th>attribute_55</th>\n",
       "      <th>attribute_56</th>\n",
       "      <th>attribute_57</th>\n",
       "      <th>attribute_58</th>\n",
       "      <th>attribute_59</th>\n",
       "      <th>attribute_60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0546</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>0.1589</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0987</td>\n",
       "      <td>0.0955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  attribute_1  attribute_2  attribute_3  attribute_4  \\\n",
       "0            1       0.0200       0.0371       0.0428       0.0207   \n",
       "1            2       0.0453       0.0523       0.0843       0.0689   \n",
       "2            3       0.0262       0.0582       0.1099       0.1083   \n",
       "3            4       0.0100       0.0171       0.0623       0.0205   \n",
       "4            5       0.0762       0.0666       0.0481       0.0394   \n",
       "5            6       0.0286       0.0453       0.0277       0.0174   \n",
       "6            7       0.0317       0.0956       0.1321       0.1408   \n",
       "7            8       0.0519       0.0548       0.0842       0.0319   \n",
       "8            9       0.0223       0.0375       0.0484       0.0475   \n",
       "9           10       0.0164       0.0173       0.0347       0.0070   \n",
       "10          11       0.0039       0.0063       0.0152       0.0336   \n",
       "11          12       0.0123       0.0309       0.0169       0.0313   \n",
       "12          13       0.0079       0.0086       0.0055       0.0250   \n",
       "13          14       0.0090       0.0062       0.0253       0.0489   \n",
       "14          15       0.0124       0.0433       0.0604       0.0449   \n",
       "\n",
       "    attribute_5  attribute_6  attribute_7  attribute_8  attribute_9  ...  \\\n",
       "0        0.0954       0.0986       0.1539       0.1601       0.3109  ...   \n",
       "1        0.1183       0.2583       0.2156       0.3481       0.3337  ...   \n",
       "2        0.0974       0.2280       0.2431       0.3771       0.5598  ...   \n",
       "3        0.0205       0.0368       0.1098       0.1276       0.0598  ...   \n",
       "4        0.0590       0.0649       0.1209       0.2467       0.3564  ...   \n",
       "5        0.0384       0.0990       0.1201       0.1833       0.2105  ...   \n",
       "6        0.1674       0.1710       0.0731       0.1401       0.2083  ...   \n",
       "7        0.1158       0.0922       0.1027       0.0613       0.1465  ...   \n",
       "8        0.0647       0.0591       0.0753       0.0098       0.0684  ...   \n",
       "9        0.0187       0.0671       0.1056       0.0697       0.0962  ...   \n",
       "10       0.0310       0.0284       0.0396       0.0272       0.0323  ...   \n",
       "11       0.0358       0.0102       0.0182       0.0579       0.1122  ...   \n",
       "12       0.0344       0.0546       0.0528       0.0958       0.1009  ...   \n",
       "13       0.1197       0.1589       0.1392       0.0987       0.0955  ...   \n",
       "14       0.0597       0.0355       0.0531       0.0343       0.1052  ...   \n",
       "\n",
       "    attribute_52  attribute_53  attribute_54  attribute_55  attribute_56  \\\n",
       "0         0.0027        0.0065        0.0159        0.0072        0.0167   \n",
       "1         0.0084        0.0089        0.0048        0.0094        0.0191   \n",
       "2         0.0232        0.0166        0.0095        0.0180        0.0244   \n",
       "3         0.0121        0.0036        0.0150        0.0085        0.0073   \n",
       "4         0.0031        0.0054        0.0105        0.0110        0.0015   \n",
       "5         0.0045        0.0014        0.0038        0.0013        0.0089   \n",
       "6         0.0201        0.0248        0.0131        0.0070        0.0138   \n",
       "7         0.0081        0.0120        0.0045        0.0121        0.0097   \n",
       "8         0.0145        0.0128        0.0145        0.0058        0.0049   \n",
       "9         0.0090        0.0223        0.0179        0.0084        0.0068   \n",
       "10        0.0062        0.0120        0.0052        0.0056        0.0093   \n",
       "11        0.0133        0.0265        0.0224        0.0074        0.0118   \n",
       "12        0.0176        0.0127        0.0088        0.0098        0.0019   \n",
       "13        0.0059        0.0095        0.0194        0.0080        0.0152   \n",
       "14        0.0083        0.0057        0.0174        0.0188        0.0054   \n",
       "\n",
       "    attribute_57  attribute_58  attribute_59  attribute_60  Class  \n",
       "0         0.0180        0.0084        0.0090        0.0032   Rock  \n",
       "1         0.0140        0.0049        0.0052        0.0044   Rock  \n",
       "2         0.0316        0.0164        0.0095        0.0078   Rock  \n",
       "3         0.0050        0.0044        0.0040        0.0117   Rock  \n",
       "4         0.0072        0.0048        0.0107        0.0094   Rock  \n",
       "5         0.0057        0.0027        0.0051        0.0062   Rock  \n",
       "6         0.0092        0.0143        0.0036        0.0103   Rock  \n",
       "7         0.0085        0.0047        0.0048        0.0053   Rock  \n",
       "8         0.0065        0.0093        0.0059        0.0022   Rock  \n",
       "9         0.0032        0.0035        0.0056        0.0040   Rock  \n",
       "10        0.0042        0.0003        0.0053        0.0036   Rock  \n",
       "11        0.0026        0.0092        0.0009        0.0044   Rock  \n",
       "12        0.0059        0.0058        0.0059        0.0032   Rock  \n",
       "13        0.0158        0.0053        0.0189        0.0102   Rock  \n",
       "14        0.0114        0.0196        0.0147        0.0062   Rock  \n",
       "\n",
       "[15 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"dataminerocks.csv\")\n",
    "dataset.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the balance on the binary response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mine    111\n",
      "Rock     97\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "occurrences = dataset['Class'].value_counts()\n",
    "print(occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.36538461538461\n"
     ]
    }
   ],
   "source": [
    "# Percent of Mines\n",
    "percMines=111/(111+97)*100\n",
    "print(percMines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.63461538461539\n"
     ]
    }
   ],
   "source": [
    "#Percent of Rocks\n",
    "percRocks=97/(111+97)*100\n",
    "print(percRocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding the response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "203    0\n",
      "204    0\n",
      "205    0\n",
      "206    0\n",
      "207    0\n",
      "Name: Class, Length: 208, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Encoding dependent variable using label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "dataset[\"Class\"]=le.fit_transform(dataset[\"Class\"])\n",
    "print(dataset[\"Class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create y and X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:, :-1].values\n",
    "y=dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00e+00 2.00e-02 3.71e-02 ... 8.40e-03 9.00e-03 3.20e-03]\n",
      " [2.00e+00 4.53e-02 5.23e-02 ... 4.90e-03 5.20e-03 4.40e-03]\n",
      " [3.00e+00 2.62e-02 5.82e-02 ... 1.64e-02 9.50e-03 7.80e-03]\n",
      " ...\n",
      " [2.06e+02 5.22e-02 4.37e-02 ... 1.38e-02 7.70e-03 3.10e-03]\n",
      " [2.07e+02 3.03e-02 3.53e-02 ... 7.90e-03 3.60e-03 4.80e-03]\n",
      " [2.08e+02 2.60e-02 3.63e-02 ... 3.60e-03 6.10e-03 1.15e-02]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For logistic regression is not necessary BUT, it tends to enhance the performance.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc=sc_X\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test =sc_X.transform(X_test) #Not fit_transform to avoid information leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00250576  0.55755787 -0.29891405 ... -0.4267949   0.10009367\n",
      "  -0.35347414]\n",
      " [ 1.49715278 -1.04478083 -1.10841889 ... -0.22144732 -0.97786942\n",
      "  -0.66857108]\n",
      " [-1.6026352  -0.27690106  0.006207   ...  0.25243171 -0.31206869\n",
      "  -0.78673244]\n",
      " ...\n",
      " [ 0.1945823  -0.25470801 -0.83131916 ... -0.50577473 -0.24865909\n",
      "  -0.45194193]\n",
      " [-0.95959408  0.38889064 -0.28646013 ... -0.36361102  0.10009367\n",
      "  -0.03837719]\n",
      " [ 1.10143517 -0.46776135  0.22103713 ... -0.4267949  -0.09013511\n",
      "  -0.78673244]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.53668226e+00 -9.16061099e-01 -8.93588761e-01 ... -3.00427154e-01\n",
      "  -3.12068688e-01 -5.89796848e-01]\n",
      " [-4.15482357e-01 -2.50269395e-01 -1.24738788e-02 ... -7.58510216e-01\n",
      "   4.01289238e-01  1.99005940e+00]\n",
      " [-1.19042935e+00  6.95154826e-01  3.23781977e-01 ...  4.41983325e-01\n",
      "  -3.12068688e-01  8.47832969e-01]\n",
      " ...\n",
      " [ 4.61881938e-02  1.39201681e+00  3.14441537e-01 ...  5.84147034e-01\n",
      "   5.28108424e-01  7.49365173e-01]\n",
      " [-1.30584699e+00 -5.96481081e-01 -1.65034406e-01 ... -9.16469892e-01\n",
      "  -8.82755028e-01  1.00992611e-03]\n",
      " [-6.92294438e-02  2.20223410e-01 -7.44141714e-01 ...  4.73848652e+00\n",
      "   7.50042001e-01  1.85220448e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating logistic regression model on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifier.predict(sc_X.transform([[30,87000]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#print(classifier.predict(sc_X.transform([[30,87000]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "np.set_printoptions(precision=0)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26,  0],\n",
       "       [ 3, 23]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 0, 3, 23)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(classifier.fit(X_train, y_train), X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy estimates the number of correct predictions among the total number of predictions made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.23076923076923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc=accuracy_score(y_test, y_pred)*100\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.23076923076923\n"
     ]
    }
   ],
   "source": [
    "acc2=(tp+tn)/(tp+fp+tn+fn)*100\n",
    "print(acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "plot_roc_curve(classifier.fit(X_train, y_train), X_test, y_test)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision answer the question: Of all the cases that the model PREDICTED as TRUE (positive), what percent was actually TRUE (positive). This is, what is the fraction of positives that were classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "pre1=precision_score(y_test, y_pred)*100\n",
    "print(pre1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "pre=(tp/(tp+fp))*100\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall answers the question: Of all the cases that were actually TRUE (positive), how many dis the model \"catch\" or predict as TRUE (positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.46153846153845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "rec=recall_score(y_test, y_pred)*100\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.46153846153845\n"
     ]
    }
   ],
   "source": [
    "rec1=tp/(tp+fn)*100\n",
    "print(rec1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 = 2 * (precision * recall) / (precision + recall) is the harmonic mean of precision and recall. \n",
    "It can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9387755102040816"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When true positive + false positive == 0, precision is undefined. When true positive + false negative == 0, recall is undefined. In such cases, by default the metric will be set to 0, as will f-score, and UndefinedMetricWarning will be raised. This behavior can be modified with zero_division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
